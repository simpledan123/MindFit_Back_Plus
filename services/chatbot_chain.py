"""
LangGraph ê¸°ë°˜ ë§›ì§‘ ì¶”ì²œ ë©€í‹°ìŠ¤í… ì—ì´ì „íŠ¸
- ì˜ë„ ë¶„ë¥˜ â†’ ì¡°ê±´ë¶€ ë¼ìš°íŒ… â†’ RAG ê²€ìƒ‰ â†’ ì‘ë‹µ ìƒì„±
- JD ë§¤ì¹­: LangChain/LangGraph ê¸°ë°˜ ë©€í‹°ìŠ¤í… ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì²´ì´ë‹, ë¼ìš°íŒ…
"""

from typing import TypedDict, Literal, List, Optional, Annotated
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document, SystemMessage, HumanMessage
from dotenv import load_dotenv
import os
import sqlite3
import operator

from crud.chatbot import get_user_summary, save_user_summary, save_user_keywords, get_user_keywords
from models.user import User
from sqlalchemy.orm import Session

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# LLM ì„¤ì •
llm = ChatOpenAI(
    openai_api_key=openai_api_key,
    model_name="gpt-4o-mini",
    temperature=0
)
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)


# ============================================
# ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì‹ë‹¹ ë°ì´í„° ë¡œë”©)
# ============================================
def init_vectorstore():
    conn = sqlite3.connect("prac.db")
    cursor = conn.cursor()
    cursor.execute("""
        SELECT id, name, address, phone, rating, latitude, longitude 
        FROM restaurants
    """)
    rows = cursor.fetchall()
    conn.close()

    documents = []
    for row in rows:
        id_, name, address, phone, rating, lat, lng = row
        content = f"""ì‹ë‹¹ëª…: {name}
ì£¼ì†Œ: {address}
ì „í™”ë²ˆí˜¸: {phone or 'ì •ë³´ì—†ìŒ'}
í‰ì : {rating}
ìœ„ë„: {lat}
ê²½ë„: {lng}"""
        documents.append(Document(
            page_content=content,
            metadata={
                "id": id_,
                "name": name,
                "address": address,
                "latitude": lat,
                "longitude": lng,
                "rating": rating
            }
        ))

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = splitter.split_documents(documents)
    return FAISS.from_documents(docs, embeddings)


vectorstore = init_vectorstore()


# ============================================
# ìƒíƒœ ì •ì˜ (State Schema)
# ============================================
class ChatState(TypedDict):
    # ì…ë ¥
    user_id: int
    message: str
    db: Session
    
    # ì¤‘ê°„ ì²˜ë¦¬
    intent: str  # "ì¶”ì²œ" | "ëŒ€í™”" | "ì„ í˜¸ë„_ì§ˆë¬¸" | "ì„ í˜¸ë„_ì €ì¥"
    summary: str
    keywords: List[str]
    location_filter: Optional[str]
    
    # RAG ê²°ê³¼
    search_results: List[Document]
    
    # ì¶œë ¥
    response: str


# ============================================
# ë…¸ë“œ í•¨ìˆ˜ë“¤
# ============================================

def load_user_context(state: ChatState) -> ChatState:
    """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ (ìš”ì•½, í‚¤ì›Œë“œ)"""
    db = state["db"]
    user_id = state["user_id"]
    
    summary_obj = get_user_summary(db, user_id)
    summary = getattr(summary_obj, "summary", "") or ""
    
    # ìš”ì•½ ê¸¸ì´ ì œí•œ (ìµœê·¼ 10ì¤„ë§Œ ìœ ì§€)
    lines = summary.strip().split("\n")
    if len(lines) > 10:
        summary = "\n".join(lines[-10:])
    
    keywords_obj = get_user_keywords(db, user_id)
    keywords = []
    if keywords_obj:
        keywords = [kw.keyword for kw in keywords_obj] if hasattr(keywords_obj, '__iter__') else []
    
    return {
        **state,
        "summary": summary,
        "keywords": keywords
    }


def classify_intent(state: ChatState) -> ChatState:
    """ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ - 4ê°€ì§€ ì˜ë„ë¡œ ë¶„ë¥˜"""
    message = state["message"]
    summary = state["summary"]
    
    # ì„ í˜¸ë„ ì§ˆë¬¸ íŒ¨í„´ ì²´í¬
    preference_ask_patterns = ["ì¢‹ì•„í•˜ëŠ” ìŒì‹", "ë‚´ê°€ ë­˜ ì¢‹ì•„", "ì·¨í–¥", "ì„ í˜¸"]
    if any(p in message for p in preference_ask_patterns):
        return {**state, "intent": "ì„ í˜¸ë„_ì§ˆë¬¸"}
    
    # ì„ í˜¸ë„ ì €ì¥ íŒ¨í„´ ì²´í¬
    preference_save_patterns = ["ì¢‹ì•„í•´", "ì‹«ì–´í•´", "ëª» ë¨¹ì–´", "ì•ŒëŸ¬ì§€", "ì„ í˜¸í•´"]
    if any(p in message for p in preference_save_patterns):
        return {**state, "intent": "ì„ í˜¸ë„_ì €ì¥"}
    
    # LLMìœ¼ë¡œ ì¶”ì²œ/ëŒ€í™” ì˜ë„ ë¶„ë¥˜
    system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ë‹¤ìŒ ì¤‘ ì–´ëŠ ì˜ë„ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”:

1. "ì¶”ì²œ" - ë§›ì§‘/ì‹ë‹¹/ìŒì‹ ì¶”ì²œì„ ì›í•˜ëŠ” ê²½ìš°
   ì˜ˆ: "ë§›ì§‘ ì¶”ì²œí•´ì¤˜", "ë­ ë¨¹ì„ê¹Œ", "ê·¼ì²˜ ì‹ë‹¹ ì•Œë ¤ì¤˜", "ì ì‹¬ ë­ ë¨¹ì§€"
   
2. "ëŒ€í™”" - ì¼ë°˜ì ì¸ ëŒ€í™”, ì¸ì‚¬, ì§ˆë¬¸ ë“±
   ì˜ˆ: "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ", "ì‹¬ì‹¬í•´"

ë°˜ë“œì‹œ "ì¶”ì²œ" ë˜ëŠ” "ëŒ€í™”" ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì‚¬ìš©ì ë©”ì‹œì§€: {message}\n\nì´ì „ ëŒ€í™” ìš”ì•½: {summary[:200] if summary else 'ì—†ìŒ'}")
    ]
    
    result = llm.invoke(messages).content.strip()
    intent = "ì¶”ì²œ" if "ì¶”ì²œ" in result else "ëŒ€í™”"
    
    return {**state, "intent": intent}


def extract_location(state: ChatState) -> ChatState:
    """ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ ë…¸ë“œ"""
    message = state["message"]
    
    # ìœ„ì¹˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    location_keywords = ["ê·¼ì²˜", "ì£¼ë³€", "ê°•ë‚¨", "í™ëŒ€", "ì´íƒœì›", "ì‹ ì´Œ", "ëª…ë™", "ì¢…ë¡œ"]
    location_filter = None
    
    for loc in location_keywords:
        if loc in message:
            location_filter = loc
            break
    
    return {**state, "location_filter": location_filter}


def rag_search(state: ChatState) -> ChatState:
    """RAG ê²€ìƒ‰ ë…¸ë“œ - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
    message = state["message"]
    keywords = state["keywords"]
    location_filter = state.get("location_filter")
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± (ì‚¬ìš©ì ë©”ì‹œì§€ + ì„ í˜¸ í‚¤ì›Œë“œ)
    search_query = message
    if keywords:
        search_query += " " + " ".join(keywords[:3])
    
    # ë²¡í„° ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)
    results = vectorstore.similarity_search(search_query, k=5)
    
    # ìœ„ì¹˜ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
    if location_filter and location_filter not in ["ê·¼ì²˜", "ì£¼ë³€"]:
        results = [
            doc for doc in results 
            if location_filter in doc.metadata.get("address", "")
        ] or results[:3]
    
    # í‰ì ìˆœ ì •ë ¬
    results = sorted(
        results, 
        key=lambda x: x.metadata.get("rating", 0), 
        reverse=True
    )[:3]
    
    return {**state, "search_results": results}


def generate_recommendation(state: ChatState) -> ChatState:
    """ì¶”ì²œ ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
    message = state["message"]
    search_results = state["search_results"]
    keywords = state["keywords"]
    
    if not search_results:
        return {
            **state, 
            "response": "ì£„ì†¡í•´ìš”, ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”!"
        }
    
    # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
    restaurant_info = "\n\n".join([
        f"[{i+1}] {doc.metadata['name']}\n"
        f"   ì£¼ì†Œ: {doc.metadata['address']}\n"
        f"   í‰ì : {doc.metadata['rating']}"
        for i, doc in enumerate(search_results)
    ])
    
    system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë§›ì§‘ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ ì‹ë‹¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”
- ê° ì‹ë‹¹ì˜ íŠ¹ì§•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”
- ì‚¬ìš©ìì˜ ì„ í˜¸ë„ê°€ ìˆë‹¤ë©´ ê·¸ì— ë§ê²Œ ì¶”ì²œ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"""

    user_content = f"""ì‚¬ìš©ì ìš”ì²­: {message}
ì‚¬ìš©ì ì„ í˜¸ í‚¤ì›Œë“œ: {', '.join(keywords) if keywords else 'ì•„ì§ íŒŒì•…ëœ ì„ í˜¸ë„ ì—†ìŒ'}

ê²€ìƒ‰ëœ ì‹ë‹¹ ì •ë³´:
{restaurant_info}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”."""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_content)
    ]
    
    response = llm.invoke(messages).content.strip()
    
    return {**state, "response": response}


def generate_conversation(state: ChatState) -> ChatState:
    """ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
    message = state["message"]
    summary = state["summary"]
    
    system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë§›ì§‘ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë˜, ìŒì‹ì´ë‚˜ ë§›ì§‘ ê´€ë ¨ ëŒ€í™”ë¡œ ìœ ë„í•´ì£¼ì„¸ìš”.
- ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”
- ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ë§›ì§‘ ì¶”ì²œì„ ì œì•ˆí•´ì£¼ì„¸ìš”"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì´ì „ ëŒ€í™” ìš”ì•½: {summary[:300] if summary else 'ì—†ìŒ'}\n\nì‚¬ìš©ì: {message}")
    ]
    
    response = llm.invoke(messages).content.strip()
    
    return {**state, "response": response}


def handle_preference_question(state: ChatState) -> ChatState:
    """ì„ í˜¸ë„ ì§ˆë¬¸ ì²˜ë¦¬ ë…¸ë“œ"""
    keywords = state["keywords"]
    
    if keywords:
        keyword_str = ", ".join(keywords)
        response = f"ì§€ê¸ˆê¹Œì§€ ëŒ€í™”ë¥¼ ë³´ë©´, {keyword_str} ê°™ì€ ìŒì‹ì„ ì¢‹ì•„í•˜ì‹œëŠ” ê²ƒ ê°™ì•„ìš”! ğŸ˜‹\ní˜¹ì‹œ ë” ì•Œë ¤ì£¼ì‹¤ ì·¨í–¥ì´ ìˆìœ¼ì‹ ê°€ìš”?"
    else:
        response = "ì•„ì§ ì·¨í–¥ì„ ì˜ ëª¨ë¥´ê² ì–´ìš”! ğŸ¤”\nì¢‹ì•„í•˜ëŠ” ìŒì‹ ì¢…ë¥˜ë‚˜ ë§›(ë§¤ìš´ë§›, ë‹¨ë§› ë“±)ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì¢‹ì€ ì¶”ì²œì„ í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”."
    
    return {**state, "response": response}


def handle_preference_save(state: ChatState) -> ChatState:
    """ì„ í˜¸ë„ ì €ì¥ ì²˜ë¦¬ ë…¸ë“œ"""
    message = state["message"]
    
    # ì„ í˜¸ë„ í‚¤ì›Œë“œ ì¶”ì¶œ
    system_prompt = """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ìŒì‹ ì„ í˜¸ë„ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ì¢‹ì•„í•˜ëŠ” ê²ƒ, ì‹«ì–´í•˜ëŠ” ê²ƒ, ëª» ë¨¹ëŠ” ê²ƒ ë“±ì„ êµ¬ë¶„í•´ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
ì˜ˆ: ë§¤ìš´ìŒì‹, í•œì‹, ê³ ê¸°"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=message)
    ]
    
    extracted = llm.invoke(messages).content.strip()
    new_keywords = [kw.strip() for kw in extracted.split(",") if kw.strip()]
    
    response = f"ì•Œê² ì–´ìš”! '{', '.join(new_keywords)}' ì·¨í–¥ì„ ê¸°ì–µí• ê²Œìš”! ğŸ“\nì´ì œ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
    
    return {
        **state, 
        "response": response,
        "keywords": list(set(state["keywords"] + new_keywords))
    }


def save_context(state: ChatState) -> ChatState:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥ ë…¸ë“œ"""
    db = state["db"]
    user_id = state["user_id"]
    message = state["message"]
    response = state["response"]
    summary = state["summary"]
    keywords = state["keywords"]
    
    # ìš”ì•½ ì—…ë°ì´íŠ¸
    new_summary = f"{summary}\n[User]: {message}\n[Bot]: {response[:100]}..."
    lines = new_summary.strip().split("\n")
    if len(lines) > 10:
        new_summary = "\n".join(lines[-10:])
    
    save_user_summary(db, user_id, new_summary)
    
    # í‚¤ì›Œë“œ ì €ì¥ (ì¶”ì²œ ì˜ë„ì˜€ì„ ê²½ìš°)
    if state["intent"] == "ì¶”ì²œ" and keywords:
        save_user_keywords(db, user_id, keywords)
    
    return state


# ============================================
# ë¼ìš°íŒ… í•¨ìˆ˜
# ============================================

def route_by_intent(state: ChatState) -> str:
    """ì˜ë„ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
    intent = state["intent"]
    
    if intent == "ì¶”ì²œ":
        return "extract_location"
    elif intent == "ì„ í˜¸ë„_ì§ˆë¬¸":
        return "handle_preference_question"
    elif intent == "ì„ í˜¸ë„_ì €ì¥":
        return "handle_preference_save"
    else:
        return "generate_conversation"


# ============================================
# ê·¸ë˜í”„ êµ¬ì„±
# ============================================

def build_chatbot_graph():
    """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
    
    workflow = StateGraph(ChatState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("load_user_context", load_user_context)
    workflow.add_node("classify_intent", classify_intent)
    workflow.add_node("extract_location", extract_location)
    workflow.add_node("rag_search", rag_search)
    workflow.add_node("generate_recommendation", generate_recommendation)
    workflow.add_node("generate_conversation", generate_conversation)
    workflow.add_node("handle_preference_question", handle_preference_question)
    workflow.add_node("handle_preference_save", handle_preference_save)
    workflow.add_node("save_context", save_context)
    
    # ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("load_user_context")
    workflow.add_edge("load_user_context", "classify_intent")
    
    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "classify_intent",
        route_by_intent,
        {
            "extract_location": "extract_location",
            "handle_preference_question": "handle_preference_question",
            "handle_preference_save": "handle_preference_save",
            "generate_conversation": "generate_conversation"
        }
    )
    
    # ì¶”ì²œ í”Œë¡œìš°
    workflow.add_edge("extract_location", "rag_search")
    workflow.add_edge("rag_search", "generate_recommendation")
    workflow.add_edge("generate_recommendation", "save_context")
    
    # ëŒ€í™” í”Œë¡œìš°
    workflow.add_edge("generate_conversation", "save_context")
    
    # ì„ í˜¸ë„ í”Œë¡œìš°
    workflow.add_edge("handle_preference_question", "save_context")
    workflow.add_edge("handle_preference_save", "save_context")
    
    # ì¢…ë£Œ
    workflow.add_edge("save_context", END)
    
    return workflow.compile()


# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbot_graph = build_chatbot_graph()


# ============================================
# API ì—”ë“œí¬ì¸íŠ¸ìš© í•¨ìˆ˜
# ============================================

def generate_chat_response(user: User, message: str, db: Session) -> dict:
    """
    FastAPI ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    ê¸°ì¡´ chatbot_chain.pyì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
    """
    
    initial_state: ChatState = {
        "user_id": user.id,
        "message": message,
        "db": db,
        "intent": "",
        "summary": "",
        "keywords": [],
        "location_filter": None,
        "search_results": [],
        "response": ""
    }
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    result = chatbot_graph.invoke(initial_state)
    
    return {"response": result["response"]}
