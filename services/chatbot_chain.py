import os
import sqlite3
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationSummaryMemory
from langchain.schema import Document, SystemMessage, HumanMessage
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# 2. LangChain êµ¬ì„±
llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-3.5-turbo", temperature=0)
memory = ConversationSummaryMemory(llm=llm, return_messages=True)
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

# 3. SQLite ì—°ê²° ë° í…Œì´ë¸” ì¤€ë¹„
conn = sqlite3.connect("prac.db")
cursor = conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS user_summary (
    user_id TEXT PRIMARY KEY,
    summary TEXT
)""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS user_keywords (
    user_id TEXT,
    keyword TEXT,
    count INTEGER DEFAULT 1,
    PRIMARY KEY (user_id, keyword)
)""")

# 4. ì‹ë‹¹ ì •ë³´ ë²¡í„°í™”
cursor.execute("SELECT id, name, latitude, longitude, rating, kakao_rating, address, phone FROM restaurants")
rows = cursor.fetchall()
documents = []
for row in rows:
    id_, name, lat, lng, rating, kakao_rating, address, phone = row
    content = f"""ì‹ë‹¹ëª…: {name}
ì£¼ì†Œ: {address}
ì „í™”ë²ˆí˜¸: {phone}
ì¹´ì¹´ì˜¤ í‰ì : {kakao_rating}
êµ¬ê¸€ í‰ì : {rating}
"""
    documents.append(
        Document(page_content=content, metadata={
            "id": id_, "latitude": lat, "longitude": lng,
            "rating": rating, "kakao_rating": kakao_rating
        })
    )
docs = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(documents)
vectorstore = FAISS.from_documents(docs, embeddings)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), return_source_documents=True)

# 5. ìœ í‹¸ í•¨ìˆ˜
def load_summary(user_id):
    cursor.execute("SELECT summary FROM user_summary WHERE user_id=?", (user_id,))
    row = cursor.fetchone()
    return row[0] if row else ""

def save_summary(user_id, summary):
    cursor.execute("REPLACE INTO user_summary (user_id, summary) VALUES (?, ?)", (user_id, summary))
    conn.commit()

def save_keywords(user_id, keywords):
    for kw in keywords:
        cursor.execute("""
        INSERT INTO user_keywords (user_id, keyword, count)
        VALUES (?, ?, 1)
        ON CONFLICT(user_id, keyword) DO UPDATE SET count = count + 1
        """, (user_id, kw))
    conn.commit()

def extract_keywords_from_summary(summary):
    messages = [
        SystemMessage(content="ë‹¤ìŒ ìš”ì•½ì—ì„œ ì‚¬ìš©ìì˜ ìŒì‹ ì·¨í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 3~5ê°œë§Œ ì‰¼í‘œë¡œ ì¶”ì¶œí•´ì¤˜."),
        HumanMessage(content=summary)
    ]
    result = llm(messages).content.strip()
    return [kw.strip() for kw in result.split(",") if kw.strip()]

def classify_intent(query, summary):
    messages = [
        SystemMessage(content=f"""ì´ ì‚¬ìš©ìì˜ ìš”ì•½ ì •ë³´: {summary}
ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•´ì¤˜:
1. ë©”ë‰´ì¶”ì²œ
2. ì‹ë‹¹ì¶”ì²œ
3. ì •ë³´ì…ë ¥
ìœ„ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ë§Œ ë§í•´ì¤˜."""),
        HumanMessage(content=query)
    ]
    return llm(messages).content.strip()

# 6. ì±—ë´‡ ë©”ì¸ í•¨ìˆ˜
def generate_chat_response(query, user_id="default_user"):
    summary = load_summary(user_id)
    intent = classify_intent(query, summary)

    if intent == "ì •ë³´ì…ë ¥":
        memory.save_context({"input": query}, {"output": "ì…ë ¥ ì™„ë£Œ!"})
        updated_summary = memory.predict_new_summary(memory.chat_memory.messages, summary)
        keywords = extract_keywords_from_summary(updated_summary)
        save_keywords(user_id, keywords)
        save_summary(user_id, updated_summary)
        return {"answer": f"ë‹¹ì‹ ì˜ ì„ í˜¸ë¥¼ ì €ì¥í–ˆì–´ìš”: {', '.join(keywords)}"}

    elif intent == "ì‹ë‹¹ì¶”ì²œ":
        result = qa_chain({"query": query})
        return {"answer": result["result"]}

    elif intent == "ë©”ë‰´ì¶”ì²œ":
        menu = query.replace("ë¨¹ê³ ì‹¶ì–´", "").strip()
        result = qa_chain({"query": f"{menu} ì˜í•˜ëŠ” ì§‘ ì•Œë ¤ì¤˜"})
        return {"answer": result["result"]}

    else:
        return {"answer": "ì£„ì†¡í•´ìš”, ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ë§í•´ì£¼ì‹œê² ì–´ìš”?"}

# 7. í…ŒìŠ¤íŠ¸ìš© CLI
if __name__ == "__main__":
    print("ğŸ“ ì±—ë´‡ ì‹œì‘! (ì¢…ë£Œí•˜ë ¤ë©´ 'exit')")
    while True:
        q = input("ë‹¹ì‹ : ")
        if q.strip().lower() in ["exit", "quit"]:
            break
        res = generate_chat_response(q)
        print(res["answer"])
